\documentclass[a4paper,12pt]{report}
\usepackage[italian]{babel}
\usepackage[latin1]{inputenc}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{empheq}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{breakurl}
\setcounter{tocdepth}{2}
\begin{document}

%\begin{figure}
%\centering
%\includegraphics[scale=0.15]{Logo.jpg}
%\end{figure}
\begin{center}
\textbf{UNIVERSIT\'{A} DEGLI STUDI "ROMA TRE"}\\
\vspace{0.3cm}
\textmd{\large Dipartimento di Matematica e Fisica}\\
\vspace{0.2cm}
\large{ Corso di Laurea Magistrale in Scienze Computazionali}\\	
\vspace{1.4cm}	
\textmd{\Large{Tesi di Laurea Magistrale}}\\
\vspace{1.6cm}
\LARGE{\LARGE{\textbf{Ricerca della tolopologia ottimale di un sistema di deep learning per identificazioni di oggetti architettonici}}}\\
\vspace{5cm}
\begin{tabular}{ccccccccccc}
	\large{Candidato}& & & & & & & & & & \large{Relatore}\\
	\large{Dèsirèe Adiutori} & & & & & & & & & &\large{Prof. Alberto Paoluzzi}
\end{tabular}\\
\vspace{4cm}
\normalsize{Anno Accademico 2017/2018}\\
\normalsize{Luglio 2018}
\end{center}
\newpage
\tableofcontents
\newpage
\section*{Introduzione}
\addcontentsline{toc}{section}{Introduzione}
Dall'invenzione dei computer, l'uomo fa sempre più affidamento sulle macchine per risolvere problemi complessi di calcolo. Con l'aumentare delle prestazioni dei computer, man mano si sono sviluppati algoritmi di calcolo sempre più efficienti.
Nel 1959 l'ingegnere del MIT, Arthur Samuel coniò il termine \textit{"machine learning"}, descrivendo l'apprendimento automatico come un "campo di studio che dà ai computer la possibilità di apprendere senza essere programmati esplicitamente per farlo".\cite{Samuel} \\
Definiamo l'apprendimento automatico come un insieme di metodi in grado di rilevare automaticamente i modelli tramite dei dati e quindi utilizzare i modelli scoperti per prevedere i dati futuri o per eseguire altri tipi di processi decisionali in condizioni di incertezza. L'insegnamento alla macchina è, pertanto, imprescindibile dai dati. Generalmente, più dati si passano alla macchina, più può imparare. Per questo motivo con l'avvento di Internet, dagli anni '90 ad oggi il tema del "machine learning" è diventato sempre più attuale, la mole di dati reperibile dal web è cospicuo e ha permesso che questo campo sia esponenzialmente progredito.\\
Il \textit{"deep learning"} è un tipo particolare di machine learning, che riguarda l'emulazione di come gli esseri umani apprendono. Esso affronta i problemi del machine learning, rappresentando il mondo come una gerarchia di concetti annidati: ogni concetto è definito in relazione a concetti più semplici e le rappresentazioni astratte vengono calcolate in termini di concetti meno astratti. Il Deep Learning implica l'utilizzo di reti neurali artificiali (\textit{deep artificial neural networks}), algoritmi e sistemi computazionali, ispirati al cervello umano, per affrontare i problemi del Machine Learning.\\
L'analogia di Shehzad Noor Taus Priyo può aiutare a capire meglio cosa siano le reti neurali:\\
"Immaginiamole come una serie di porte da oltrepassare, dove l'input è l'uomo che le deve oltrepassare e ogni volta che lo fa cambia qualcosa nel suo comportamento finchè, all'ultima porta oltrepassata, l'uomo è diventato una persona del tutto differente, rappresentando l'output di questo processo."\cite{analogia} \\
Questa tesi si focalizza su un problema %tipo
particolare di algoritmo di machine learning: la Classificazione (\textit{Classification}), in particolar modo della classificazione di immagini. L'obiettivo principale è trovare un'architettura ottimale per l'algoritmo che identifica le immagini di oggetti architettonici, per fare questo bisogna trovare la giusta topologia, la giusta profondità e la giusta larghezza di ogni livello della rete neurale.
 
\chapter{Algoritmi di apprendimento}
Gli algoritmi di machine learning sono solitamente divisi in tre tipi principali:
\begin{itemize}
\item Supervised learning (apprendimento supervisionato)
\item Unsupervised learning (apprendimento non supervisionato)
\item Reinforcement learning (apprendimento per rinforzo)
\end{itemize}
Quali usare? Perchè sceglierne uno piuttosto che un altro?\\
La scelta dell'algoritmo da utilizzare dipende dal tipo di dati di cui si dispone. Ma la scelta finale va fatta solo esclusivamente dopo aver testato l'algoritmo, e si sceglie in base a quello più performante: un insieme di ipotesi che funziona bene in un dominio, potrebbe funzionare male in un altro.\\
\textbf{Teorema del No Free Lunch \cite[Wolper,1996]{NFL}}\\
\textit{Non esiste una definizione universale di algoritmo "migliore".}
\section{Costruzione di un algoritmo di apprendimento}\label{Costruzione di un algoritmo di apprendimento}
Per costruire un algoritmo di apprendimento bisogna avere:
\begin{itemize}
\item processi(\textit{task}), compiti che l'algoritmo deve eseguire;
\item misuratori di rendimento, rilevatori delle caratteristiche dei processi;
\item esperienze, quantità di dati dal quale imparare.
\end{itemize}
I processi di apprendimento automatico descrivono come il sistema dovrebbe elaborare un esempio.
\newtheorem{defin}{Definizione}
\begin{defin}
Un \textbf{esempio} è una raccolta di caratteristiche che sono state misurate quantitativamente da alcuni oggetti o eventi elaborati.
\end{defin}
Di solito, un esempio viene rappresentato da un vettore $x\in \mathbb{R}^{n}$, dove ogni elemento $x_{i}$ rappresenta una caratteristica.
Dato un processo si cerca di capire quale sia la caratteristica principale, sulla quale si deve misurare il suo rendimento.
Infine, dobbiamo dare all'algoritmo un'esperienza sulla quale apprendere, che è quella che lo classificherà in uno dei tre tipi principali.
Questa esperienza l'apprende dai \textit{dataset}: una collezione di esempi.\\
I dataset possono essere di vari tipi:
\begin{itemize}
\item insieme di addestramento ( \textit{training set})
\item insieme di prova ( \textit{test set})
\item insieme di validazione ( \textit{validation set})
\end{itemize}
L' \textbf{insieme di addestramento} è una parte dell'insieme di dati che vengono utilizzati per addestrare un sistema di apprendimento supervisionato. Da questo insieme, l'algoritmo deve costruire una funzione che capisca, dai parametri, quali caratteristiche descrivono le varie categorie.\\
L' \textbf{insieme di prova} è un insieme di dati che, con l'insieme di addestramento, forma una partizione del dataset di partenza. Questi nuovi dati vengono utilizzati per valutare l'apprendimento dell'algoritmo "addestrato".\\
L' \textbf{insieme di validazione} è usato in maniera analoga all'insieme di prova, ma dei dati inseriti per testare l'algoritmo già si conosce la risposta (una parte di essi può far parte dell'insieme di addestramento) e da questa si valuta se l'output ottenuto è ottimale o meno.\\
Questi tre insiemi possono essere usati anche tutti e tre contemporaneamente. La scelta della cardinalità dei vari sottoinsiemi non è universale e dipende dal tipo di problema che viene affrontato.\\
Vediamo ora come valutare l'efficienza di un algoritmo:
\begin{defin}
L'\textbf{errore di allenamento}(\textit{training error}) è una misura di errore che si può calcolare sul set di allenamento. Indica quanto l'algortimo sta apprendendo.
\end{defin}
\begin{defin}
La \textbf{generalizzazione} è la capacità di un algoritmo di essere ottimale in seguito ad un input proveniente dall' insieme di prova.
\end{defin}
\begin{defin}
L'\textbf{errore di generalizzazione}(\textit{generalization error}) è una misura di errore che si può calcolare sull'insieme di prova. Verifica se l'algoritmo ha imparato o solo memorizzato.
Esso viene detto anche errore di test (\textit{test error}).
\end{defin}
Ipotizziamo che tutti gli esempi siano eventi indipendenti e che tuti gli insiemi, in cui partizioniamo l'insieme di dati, hanno la stessa distribuzione di probabilità uniforme.
\begin{defin}
Una \textbf{funzione di perdita} (\textit{loss function}) $L(y,\hat{y})$ è una funzione che misura la distanza (o l'errore) tra i valori di output previsto $\hat{y}$ e i valori effettivi ${y}$.
\end{defin}
Si possono usare varie misure, per esempio nel caso dell'errore quadratico medio(MSE):
\begin{equation}\label{train-error}
L(y,\hat{y})_{train}=\frac{1}{n}\sum_{i=1}^{n}(\hat{y}_{(train)}-y_{(train)})_{i}^2
\end{equation}
La nostra funzione di predizione dipenderà da dei parametri, rappresentati da un vettore $w$, lo scopo è di minimizzare l'errore di allenamento variando $w$.
In base al tipo di apprendimento e al problema da affrontare verranno usati vari algoritmi per risolvere problemi di minimizzazione libera. Ovvero gli algoritmi per risolvere il problema: $$f(x^{*})=\min_{x\in \mathbb{R}^{n}}f(x),\qquad \qquad f\in C^{2}$$
Ad esempio verrà spesso utilizzato il metodo di discesa del gradiente.\cite{an}\\
La struttura generale di un metodo di discesa iterativo di minimizzazione è:
\begin{equation}\label{eq:min}
x_{k+1}=x_{k}+\beta_{k}d_{k}
\end{equation}
dove $x_{0}$ è assegnato, $\beta_{k}\in \mathbb{R^{+}}$ è il passo e $d_{k}\in \mathbb{R}^{n}$ è la direzione lungo la quale ci si muove, che essendo una direzione di discesa sarà $(d_{k},\nabla f(x_{k}))<0$. Sia il passo che la direzione vanno scelti opportunamente ad ogni passo, in modo che $f(x_{k+1})<f(x_{k})$.\\
Il passo viene scelto in modo che si abbia:
$$f(x_{k}+\beta_{k}d_{k})=\min_{\beta}\{f(x_{k}+\beta d_{k})\}\qquad \qquad (strategia\: di\: ricerca\: esatta)$$
Mentre la scelta della direzione é $d_{k}=-\nabla f(x_{k})$. La derivata direzionale di $f$ nella direzione $d_{k}$ vale $$\frac{\partial f}{\partial d_{k}}(x_{k})=\frac{(d_{k},\nabla f(x_{k}))}{\parallel d_{k}\parallel}=-\parallel \nabla f(x_{k})\parallel$$ e per la disuguaglianza di Cauchy-Schwartz si ha anche: $$\frac{\mid (d_{k},\nabla f(x_{k}))\mid}{\parallel d_{k}\parallel}\leq \frac{\parallel d_{k}\quad \parallel \parallel \nabla f(x_{k})\parallel}{\parallel d_{k}\parallel}=\parallel \nabla f(x_{k})\parallel$$ che mostra come la direzione di ricerca sia quella in cui la derivata direzionale di $f$ è negativa e di modulo massimo.\\
Le condizioni di arresto del metodo sono: $\parallel x_{k+1}-x{k}\parallel \leq m$, $\parallel \nabla f(x_{k+1})\parallel \leq m\prime$ oppure $k>k_{max}$, dove $m$ e $m\prime$ sono soglie date e $k_{max}$ il numero massimo di iterazioni da effettuare.\\
I risultati ottenuti sono garantiti dai seguenti teoremi di convergenza:
\newtheorem{teo}{Teorema}
\begin{teo}
Sia $f(x)\in C^{1}$, strettamente convessa sull'insieme $\Sigma_{0}=\{x\in\mathbb{R}^{n}:f(x)\leq f(x_{0})\}$, e la successione $\{x_{k}\}$ sia generata tramite l'algoritmo (\ref{eq:min}). Si supponga
\begin{enumerate}
\item che l'insieme $\Sigma_{0}$ sia compatto;
\item che le direzioni $d_{k}$ siano t.c. $\frac{(d_{k},\nabla f(x_{k}))}{\parallel d_{k}\quad \parallel \parallel \nabla f(x_{k})\parallel}\leq - \cos \theta$ per $k\in \textit{I}$, con $\textit{I}$ insieme illimitato di indici;
\item che per $k\in \textit{I}$, $\beta_{k}$ sia ottenuto tramite ricerca esatta.
\end{enumerate}
Allora la successione $\{x_{k}\}$ converge all'unico punto $x^{*}$ di minimo per $f$.
\end{teo}
\begin{teo}
Sia $f(x)\in C^{2}$, strettamente convessa sull'insieme (che si suppone compatto) $\Sigma_{0}=\{x\in\mathbb{R}^{n}:f(x)\leq f(x_{0})\}$, e la successione $\{x_{k}\}$ sia generata tramite l'algoritmo (\ref{eq:min}), con $d_{k}=-\nabla f(x_{k})$.\\
Allora, se i passi $\beta_{k}$ sono determinati tramite ricerca esatta, la successione $x_{k}$ converge all'unico punto $x^{*}$ di minimo per f.
\end{teo}
Minimizzare l'errore di allenamento non necessariamente comporta l'ottimizzazione di apprendimento dell'algoritmo, potrebbe verificarsi il fenomeno di adattamento insufficiente (\textit{underfitting}),ovvero non si hanno abbastanza dati per creare un modello di predizione accurato . Bisogna quindi valutare anche altri fattori: analizzare l'insieme di prova.\\
Ricordandoci dell'eq.\ref{train-error}, calcoliamo l'errore di prova:
\begin{equation}\label{test-error}
L(y,\hat{y})_{test}=\frac{1}{n}\sum_{i=1}^{n}(\hat{y}_{(test)}-y_{(test)})_{i}^2
\end{equation}
Vorremmo che ,con i parametri trovati per minimizzare l'errore di allenamento, anche questo errore sia minimo (l'ottimalità è 0). Ma come detto in precedenza non sempre questo accade, vorremmo quindi che il divario tra i due errori sia minimo. In caso contrario si verifica il fenomeno di adattamento eccessivo (\textit{overfitting}) del modello all'insieme di dati che descrive, tramite un eccessivo numero di parametri. Il modello quindi non sarà generalizzabile ad un nuovo insieme di dati.\\
Consideriamo il valore atteso dell'errore di prova, calcolato prendendo una coppia di punti $(X,Y)$dall'insieme di prova:
\begin{equation}\label{test}
\mathbb{E} [L(y,\hat{y})_{test}]=\mathbb{E} [(Y-\hat{y}(X))^{2}]
\end{equation}
e definiamo la funzione dell'output effettivo come:
$$y(X)=\mathbb{E}(Y|X)$$
la quale avrà sicuramente un errore, dovuto da qualche interferenza che chiameremo: distorzione stimata (\textit{estimation bias}).\\
Ma con diversi insiemi di allenamento, possiamo costruire diverse funzioni $\hat{y}$, e anche questo è un'altra fonte di errore: la varianza stimata (\textit{estimation variance}). Possiamo quindi scrivere l'output come:
$$Y=y(X)+\epsilon$$ con $\epsilon$ indipendente da $X$ tale che $\mathbb{E}[X]=0$ e $Var(X)=\sigma^{2}$.\\
Possiamo quindi riscrivere l'equazione \ref{test} come:
\begin{eqnarray}
\mathbb{E} [L(y,\hat{y})_{test}] &=&\mathbb{E} [(Y-\hat{y}(X))^{2}|X=x]\nonumber\\
&=&\mathbb{E}[(Y-y(x))^2 |X=x]+\mathbb{E}[(y(x)-\hat{y}(x))^{2}|X=x]\nonumber\\
&=&\sigma^{2}+\mathbb{E}[(y(x)-\hat{y}(x))^{2}]
\end{eqnarray}
dove $\sigma^{2}$ è chiamato errore Bayes e
\begin{eqnarray}
\mathbb{E}[(y(x)-\hat{y}(x))^{2}]&=&(\mathbb{E}[\hat{y}(x)]-y(x))^{2}+\mathbb{E}[(\hat{y}(x)-\mathbb{E}[\hat{y}(x)])^{2}]\nonumber\\
&=&Bias(\hat{y}(x))^{2}+Var(\hat{y}(x))
\end{eqnarray}
Si ottiene così il compromesso distorzione-varianza (\textit{bias-variance tradeoff}):
\begin{equation}
\mathbb{E} [L(y,\hat{y})_{test}]=\sigma^2+Bias(\hat{y}(x))^2 + Var(\hat{y}(x))
\end{equation}
Se la distorzione ha valori alti e la varianza bassi avremo un fenomeno di adattamento insufficiente, mentre se la distorzione ha valori bassi e la varianza alti avremo un adatteamento eccessivo.\cite{errval}
Un modo per equilibrare questo compromesso è usare la convalida incrociata (\textit{Cross-Validation}), che consiste nel ripetere l'addestramento e il test dell'algoritmo ogni volta su sottoinsiemi scelti in maniera casuale.\\
Alcune varianti di convalida incrociata verranno analizzate in seguito.

\section{Apprendimento supervisionato}
Gli algoritmi di apprendimento supervisionato vengono utilizzati per risolvere problemi di classificazione e di regressione, che analizzeremo rispettivamente nel cap. \ref{classificazione} e nel paragrafo \ref{regressione}.
Si parla di apprendimento supervisionato quando il dataset che si utilizza contiene delle variabili, una delle quali è un'etichetta. Dato un vettore di input $x=(x_{1},\cdots,x_{n})$, ogni $x_{i}$ è un vettore d-dimensionale di numeri rappresentanti una caratteristica, da questi dati si costruisce l'insieme di addestramento di cardinalità N: $D={\{ (x_{i},y_{i})\}}^{N}_{i=1}$, dove $y=(y_{1},\cdots,y_{m})$ è l'output dei risultati desiderati e $y_{i}$ è l'etichetta.
Lo scopo è di apprendere una regola generale che colleghi i dati in ingresso con quelli in uscita, in modo che l'algoritmo apprenda a classificare un esempio completamente nuovo, non contenente l'etichetta.\\
Se $y_{i}$ è di tipo testuale si parla di classificazione, quando invece è di tipo numerico si parla di regressione. Se indichiamo con C il numero delle classi a cui può appartenere l'output: $y\in \{1,...,C\}$, se $C=2$ la classificazione sarà binaria (in questo caso spesso $y\in \{0,1\}$); se $C>2$ sarà multiclasse.\\

\subsection{Regressione}\label{regressione}
La Regressione prevede il valore futuro di un dato, avendo noto il suo valore attuale. Un esempio è la previsione della quotazione delle valute o delle azioni di una società. Nel marketing viene utilizzato per prevedere il tasso di risposta di una campagna sulla base di un dato profilo di clienti; nell'ambito commerciale per stimare come varia il fatturato dell'azienda al mutare della strategia. Questo avviene costruendo una funzione che meglio si adatta ai
punti che descrivono la distribuzione delle Y sulle X. 
\subsubsection{Regressione lineare}
Preso un vettore $x\in \mathbb{R}^{n}$ in input, l'algoritmo cerca di prevedere l'output: $y\in \mathbb{R}$. Dove $y=f(x)$, con $f$ una funzione lineare:
\begin{flushright}
$y=\alpha+\beta x \qquad \qquad (retta\;di\;regressione)$
\end{flushright}
Sia $\hat{y}$ il valore di output che l'algoritmo prevede. Definiamo l'output come:
$$\hat{y}=\alpha+\beta x+\epsilon$$
dove $\epsilon$ è la componente di errore.\\
Ora per identificare la retta che meglio si adatta ai punti, che descrivono la distribuzione delle $y$ sulle $x$, bisogna stimare i valori dei parametri $\alpha$ e $\beta$, tramite i dati ossrvati su un esempio.\\
Usiamo il metodo dei minimi quadrati (\textit{least squares}), che minimizza l'errore $\epsilon$.
\begin{eqnarray}
\sum_{i=1}^{n}(\hat{y}_{i}-y_{i})^{2}&=&\sum_{i=1}^{n}(\hat{y}_{i}-(\alpha+\beta x_{i}))^{2}\nonumber \\
&=&\sum_{i=1}^{n}(\hat{y}_{i}-\alpha-\beta x_{i})^{2}=\min \nonumber
\end{eqnarray}
Per trovare i valori di $\alpha$ e $\beta$ risolviamo il sistema:
\begin{empheq}[left=\empheqlbrace]{align}
\frac{d (\, \sum_{i=1}^{n}(\hat{y}_{i}- \alpha - \beta x_{i})^{2})}{d \, \alpha} = 0 \label{a} \\
\frac{d (\, \sum_{i=1}^{n}(\hat{y}_{i}- \alpha - \beta x_{i})^{2})}{d \, \beta} = 0 \label{b}
\end{empheq}
Dalla (\ref{a}) otteniamo:
$$\alpha=\mathbb{E}[y]-\beta \mathbb{E}[x]$$
e dalla (\ref{b}):
$$\beta=\frac{\sum_{i=1}^{n}(x_{i}-\mathbb{E}[x])(y_{i}-\mathbb{E}[y])}{\sum_{i=1}^{n}(x_{i}-\mathbb{E}[x])^2}=\frac{Cov(x,y)}{Var(x)}$$
ottenendo così i valori dei parametri che cercavamo.\\


\section{Apprendimento non supervisionato}
Gli algoritmi di apprendimento non supervisionato vengono utilizzati per risolvere problemi di raggruppamento.
All'algoritmo viene passato solo l'input: $D={\{ x_{i}\}}^{N}_{i=1}$ e cerca una relazione tra i dati per capire se e come essi siano collegati tra di loro. Non contenendo alcuna informazione preimpostata, l'algoritmo è chiamato a creare una "nuova conoscenza" (\textit{knowledge discovery}). A differenza del caso supervisionato, questo apprendimento non ha una classificazione o un risultato finale con il quale determinare se il risultato è attendibile, ma generalizza le caratteristiche dei dati e in base ad esse attribuisce ad un input un output: serve generalmente ad estrarre informazioni non ancora note, "creando" esso stesso delle classi in cui dividere i dati. Questa tecnica si chiama \textit{clustering}.

\section{Apprendimento per rinforzo}
Gli algoritmi di apprendimento per rinforzo vengono utilizzati per risolvere problemi di regressione.
Lo scopo di questo algoritmo è di realizzare un sistema in grado di apprendere ed adattarsi ai cambiamenti dell'ambiente in cui si trovano, attraverso la distribuzione di una "ricompensa" detta rinforzo, data dalla valutazione delle prestazioni. Questi algoritmi sono costruiti sull'idea che i risultati corretti dovrebbero essere ricordati, per mezzo di un segnale di rinforzo, in modo che diventino più probabili e quindi più facilmente riottenuti nelle volte future; viceversa se il rusultato è errato , il segnale sarà una penalità, ovvero si avrà una probabilità più bassa legata a quel determinato output.\cite{rinforzo}

\chapter{Reti neurali}
\chapter{Classificazione}\label{classificazione}
La Classificazione viene usata quando è necessario decidere a quale categoria appartiene un determinato dato.Per esempio, data una foto capire a quale categoria appartiene, in questo caso capire a quale tipo di monumento appartiene.\\ 
Questo tipo di algoritmo deve specificare a quale delle k categorie appartiene un input. Crea una funzione $f:\mathbb{R}^{n} \rightarrow \{ 1,\cdots,k\}$, quando $y=f(x)$, il modello assegna l'input descritto dal vettore $x$ ad una categoria identificata dal codice numerico $y$. Esistono altre varianti dell'attività di classificazione, ad esempio, dove $f$ genera una distribuzione di probabilità su classi.
\chapter{TensorFlow}
\clearpage
\addcontentsline{toc}{chapter}{Bibliografia}
\bibliographystyle{unsrt}
\bibliography{bibliografia}
\nocite{deep,machine}
\end{document}
